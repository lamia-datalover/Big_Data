{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "242a44ae-d883-4e8e-ac5e-57d01dd63488",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The goal of this project is to manipulate deeply nested json data and transform them into structured data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56fa1394-84ae-46bf-9bc4-1a43c435a5e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading from S3\n",
    "filepath = \"s3://full-stack-bigdata-datasets/Big_Data/YOUTUBE/songs.json\"\n",
    "df = spark.read.format('json').load(filepath, multiline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9bc0160-0578-4e09-8e92-c2208712d7a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- etag: string (nullable = true)\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- contentDetails: struct (nullable = true)\n |    |    |    |-- caption: string (nullable = true)\n |    |    |    |-- contentRating: struct (nullable = true)\n |    |    |    |    |-- ytRating: string (nullable = true)\n |    |    |    |-- definition: string (nullable = true)\n |    |    |    |-- dimension: string (nullable = true)\n |    |    |    |-- duration: string (nullable = true)\n |    |    |    |-- licensedContent: boolean (nullable = true)\n |    |    |    |-- projection: string (nullable = true)\n |    |    |    |-- regionRestriction: struct (nullable = true)\n |    |    |    |    |-- allowed: array (nullable = true)\n |    |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |    |-- blocked: array (nullable = true)\n |    |    |    |    |    |-- element: string (containsNull = true)\n |    |    |-- etag: string (nullable = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- kind: string (nullable = true)\n |    |    |-- snippet: struct (nullable = true)\n |    |    |    |-- categoryId: string (nullable = true)\n |    |    |    |-- channelId: string (nullable = true)\n |    |    |    |-- channelTitle: string (nullable = true)\n |    |    |    |-- defaultAudioLanguage: string (nullable = true)\n |    |    |    |-- defaultLanguage: string (nullable = true)\n |    |    |    |-- description: string (nullable = true)\n |    |    |    |-- liveBroadcastContent: string (nullable = true)\n |    |    |    |-- localized: struct (nullable = true)\n |    |    |    |    |-- description: string (nullable = true)\n |    |    |    |    |-- title: string (nullable = true)\n |    |    |    |-- publishedAt: string (nullable = true)\n |    |    |    |-- tags: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- thumbnails: struct (nullable = true)\n |    |    |    |    |-- default: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- high: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- maxres: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- medium: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- standard: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |-- title: string (nullable = true)\n |    |    |-- statistics: struct (nullable = true)\n |    |    |    |-- commentCount: string (nullable = true)\n |    |    |    |-- dislikeCount: string (nullable = true)\n |    |    |    |-- favoriteCount: string (nullable = true)\n |    |    |    |-- likeCount: string (nullable = true)\n |    |    |    |-- viewCount: string (nullable = true)\n |    |    |-- status: struct (nullable = true)\n |    |    |    |-- embeddable: boolean (nullable = true)\n |    |    |    |-- license: string (nullable = true)\n |    |    |    |-- madeForKids: boolean (nullable = true)\n |    |    |    |-- privacyStatus: string (nullable = true)\n |    |    |    |-- publicStatsViewable: boolean (nullable = true)\n |    |    |    |-- uploadStatus: string (nullable = true)\n |    |    |-- topicDetails: struct (nullable = true)\n |    |    |    |-- relevantTopicIds: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- topicCategories: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |-- kind: string (nullable = true)\n |-- pageInfo: struct (nullable = true)\n |    |-- resultsPerPage: long (nullable = true)\n |    |-- totalResults: long (nullable = true)\n\nOut[2]: 3907"
     ]
    }
   ],
   "source": [
    "# Tidying up\n",
    "# Fixing rows\n",
    "df.printSchema()\n",
    "from pyspark.sql import functions as F\n",
    "df.select(F.explode('items')).count()\n",
    "items_df = df.select(F.explode('items').alias('items'))\n",
    "items_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2f17276-5f15-4cc9-8df0-3df20e8ac59d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/pandas/conversion.py:122: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Unable to convert the field items. If this column is not necessary, you may consider dropping it or converting to primitive type before the conversion.\nDirect cause: Nested StructType not supported in conversion to Arrow\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((false, (None,), sd, 2d, PT3M33S, True, recta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((false, (None,), hd, 2d, PT7M46S, False, rect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((false, (None,), sd, 2d, PT3M7S, False, recta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((false, (None,), hd, 2d, PT3M43S, False, rect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((false, (None,), hd, 2d, PT5M, False, rectang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>items</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>((false, (None,), sd, 2d, PT3M33S, True, recta...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>((false, (None,), hd, 2d, PT7M46S, False, rect...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>((false, (None,), sd, 2d, PT3M7S, False, recta...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>((false, (None,), hd, 2d, PT3M43S, False, rect...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>((false, (None,), hd, 2d, PT5M, False, rectang...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We're making progress, we now have one row per result (e.g. song)!\n",
    "# But each song is a deeply nested structure..I will take care of this .\n",
    "items_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11340e57-0d15-439b-b74a-c572a09d03a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: 100"
     ]
    }
   ],
   "source": [
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a25d806-2955-451a-880a-d641b6817e05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- etag: string (nullable = true)\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- contentDetails: struct (nullable = true)\n |    |    |    |-- caption: string (nullable = true)\n |    |    |    |-- contentRating: struct (nullable = true)\n |    |    |    |    |-- ytRating: string (nullable = true)\n |    |    |    |-- definition: string (nullable = true)\n |    |    |    |-- dimension: string (nullable = true)\n |    |    |    |-- duration: string (nullable = true)\n |    |    |    |-- licensedContent: boolean (nullable = true)\n |    |    |    |-- projection: string (nullable = true)\n |    |    |    |-- regionRestriction: struct (nullable = true)\n |    |    |    |    |-- allowed: array (nullable = true)\n |    |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |    |-- blocked: array (nullable = true)\n |    |    |    |    |    |-- element: string (containsNull = true)\n |    |    |-- etag: string (nullable = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- kind: string (nullable = true)\n |    |    |-- snippet: struct (nullable = true)\n |    |    |    |-- categoryId: string (nullable = true)\n |    |    |    |-- channelId: string (nullable = true)\n |    |    |    |-- channelTitle: string (nullable = true)\n |    |    |    |-- defaultAudioLanguage: string (nullable = true)\n |    |    |    |-- defaultLanguage: string (nullable = true)\n |    |    |    |-- description: string (nullable = true)\n |    |    |    |-- liveBroadcastContent: string (nullable = true)\n |    |    |    |-- localized: struct (nullable = true)\n |    |    |    |    |-- description: string (nullable = true)\n |    |    |    |    |-- title: string (nullable = true)\n |    |    |    |-- publishedAt: string (nullable = true)\n |    |    |    |-- tags: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- thumbnails: struct (nullable = true)\n |    |    |    |    |-- default: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- high: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- maxres: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- medium: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |    |-- standard: struct (nullable = true)\n |    |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |-- title: string (nullable = true)\n |    |    |-- statistics: struct (nullable = true)\n |    |    |    |-- commentCount: string (nullable = true)\n |    |    |    |-- dislikeCount: string (nullable = true)\n |    |    |    |-- favoriteCount: string (nullable = true)\n |    |    |    |-- likeCount: string (nullable = true)\n |    |    |    |-- viewCount: string (nullable = true)\n |    |    |-- status: struct (nullable = true)\n |    |    |    |-- embeddable: boolean (nullable = true)\n |    |    |    |-- license: string (nullable = true)\n |    |    |    |-- madeForKids: boolean (nullable = true)\n |    |    |    |-- privacyStatus: string (nullable = true)\n |    |    |    |-- publicStatsViewable: boolean (nullable = true)\n |    |    |    |-- uploadStatus: string (nullable = true)\n |    |    |-- topicDetails: struct (nullable = true)\n |    |    |    |-- relevantTopicIds: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- topicCategories: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |-- kind: string (nullable = true)\n |-- pageInfo: struct (nullable = true)\n |    |-- resultsPerPage: long (nullable = true)\n |    |-- totalResults: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228461b7-4be3-419d-b02a-df6a00b98938",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: \"\\n    Our schema is like a tree, we want to collect all its leaves and put them neatly as columns of our DataFrame.\\nThat's called flattening a schema \""
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Our schema is like a tree, we want to collect all its leaves and put them neatly as columns of our DataFrame.\n",
    "That's called flattening a schema '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea8ec64-3591-497d-a5f3-ab1f59c8a5ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|               title|\n+--------------------+\n|[VOLO. \"L'air d'u...|\n|[BANKS - WAITING ...|\n|[OH MY DAYUM ft. ...|\n|[caravan palace -...|\n|[ALB - Whispers U...|\n+--------------------+\nonly showing top 5 rows\n\nOut[7]: DataFrame[etag: string, items: array<struct<contentDetails:struct<caption:string,contentRating:struct<ytRating:string>,definition:string,dimension:string,duration:string,licensedContent:boolean,projection:string,regionRestriction:struct<allowed:array<string>,blocked:array<string>>>,etag:string,id:string,kind:string,snippet:struct<categoryId:string,channelId:string,channelTitle:string,defaultAudioLanguage:string,defaultLanguage:string,description:string,liveBroadcastContent:string,localized:struct<description:string,title:string>,publishedAt:string,tags:array<string>,thumbnails:struct<default:struct<height:bigint,url:string,width:bigint>,high:struct<height:bigint,url:string,width:bigint>,maxres:struct<height:bigint,url:string,width:bigint>,medium:struct<height:bigint,url:string,width:bigint>,standard:struct<height:bigint,url:string,width:bigint>>,title:string>,statistics:struct<commentCount:string,dislikeCount:string,favoriteCount:string,likeCount:string,viewCount:string>,status:struct<embeddable:boolean,license:string,madeForKids:boolean,privacyStatus:string,publicStatsViewable:boolean,uploadStatus:string>,topicDetails:struct<relevantTopicIds:array<string>,topicCategories:array<string>>>>, kind: string, pageInfo: struct<resultsPerPage:bigint,totalResults:bigint>, items.snippet.title: array<string>]"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.select('items.snippet.title').show(5)\n",
    "df.withColumn('items.snippet.title', F.col('items.snippet.title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5523052-9aa1-4b31-b839-6ef4d90233cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: 'string'"
     ]
    }
   ],
   "source": [
    "'''What this functions does, is that it walk the schema of our DataFrame with a nested schema and harvest its leave. Returning them with full path like this items.snippet.title as a string.'''\n",
    "# we'll work with the schema in json format, which will be way easier to manipulate\n",
    "df.schema.jsonValue()\n",
    "df.schema.jsonValue().keys()\n",
    "# Only two keys at this stage, type and fields, let's explore the type key\n",
    "df.schema.jsonValue()[\"type\"]\n",
    "# The value associated is struct\n",
    "# let's explore the content of the other key\n",
    "df.schema.jsonValue()[\"fields\"]\n",
    "#it's a list, what's the first element?\n",
    "df.schema.jsonValue()[\"fields\"][0]\n",
    "# what keys does it have ?\n",
    "df.schema.jsonValue()[\"fields\"][0].keys()\n",
    "# the key name contains the name of the field\n",
    "df.schema.jsonValue()[\"fields\"][0][\"name\"]\n",
    "df.schema.jsonValue()[\"fields\"][0][\"type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de4e86d4-6495-4288-9920-ff08402fc474",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from typing import List, Dict, Generator, Union, Callable\n",
    "# This is actually written like a scala function\n",
    "def walkSchema(schema: Union[StructType, StructField]) -> Generator[str, None, None]:\n",
    "    \n",
    "    # we define a function _walk that produces a string generator from\n",
    "    # a dictionnary \"schema_dct\", and a string \"prefix\"\n",
    "    def _walk(schema_dct: Dict['str', Union['str', list, dict]],\n",
    "              prefix: str = \"\") -> Generator[str, None, None]:\n",
    "        assert isinstance(prefix, str), \"prefix should be a string\" # check if prefix is a string\n",
    "        \n",
    "        # this function returns \"name\" if there's no prefix and \"prefix.name\" if prefix exists\n",
    "        fullName: Callable[str, str] = lambda name: ( \n",
    "            name if not prefix else f\"{prefix}.{name}\")\n",
    "        \n",
    "        # we get the next name one level lower from the dictionnary\n",
    "        name = schema_dct.get('name', '')\n",
    "        \n",
    "        # if the type is struct then we search for the fields key\n",
    "        # if fields is there we apply the function again and dig one level deeper in\n",
    "        # the schema and set a prefix\n",
    "        if schema_dct['type'] == 'struct':\n",
    "            assert 'fields' in schema_dct, (\n",
    "                \"It's a StructType, we should have some fields\")\n",
    "            for field in schema_dct['fields']:\n",
    "                yield from _walk(field, prefix=prefix)\n",
    "        # if we have a dict type and we can't find fields then we\n",
    "        # dig one level deeper and apply the _walk function again\n",
    "        elif isinstance(schema_dct['type'], dict):\n",
    "            assert 'fields' not in schema_dct, (\n",
    "                \"We're missing some keys here\")\n",
    "            yield from _walk(schema_dct['type'], prefix=fullName(name))\n",
    "        # If we finally reached the end and found a name we yield the full name\n",
    "        elif name:\n",
    "            yield fullName(name)\n",
    "    \n",
    "    yield from _walk(schema.jsonValue())\n",
    "\n",
    "# yield as opposed to return, returns a result but does not stop the function from running, it keeps\n",
    "# running even after returning one result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434ede19-aa0f-4e57-8bc2-d15073870ae2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: <generator object walkSchema at 0x7f9caa7dd900>"
     ]
    }
   ],
   "source": [
    "col_names = walkSchema(df.schema)\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b5b5895-bd81-47b0-92ab-2baaeed3a804",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etag\nkind\npageInfo.resultsPerPage\npageInfo.totalResults\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the walked schema\n",
    "for col_name in walkSchema(df.schema):\n",
    "  print(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41c711d0-1e83-4f16-8937-32e4e13c8550",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perfect, that's all the leafs of our schema.And we can just repeat the work we did with items.snippet.title for every column of this list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "addd8492-0916-490b-b11f-13306b8008ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etag</th>\n",
       "      <th>kind</th>\n",
       "      <th>pageInfo</th>\n",
       "      <th>pageInfo.resultsPerPage</th>\n",
       "      <th>pageInfo.totalResults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0fncx_GV9jD5SKQr15LMvwuPcs</td>\n",
       "      <td>youtube#videoListResponse</td>\n",
       "      <td>{'resultsPerPage': 38, 'totalResults': 38}</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZV6LlN3-4QwaIGfe9KBxl0cJvE</td>\n",
       "      <td>youtube#videoListResponse</td>\n",
       "      <td>{'resultsPerPage': 38, 'totalResults': 38}</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ou4xXi-09RdImAeo1EFJC01i8iM</td>\n",
       "      <td>youtube#videoListResponse</td>\n",
       "      <td>{'resultsPerPage': 43, 'totalResults': 43}</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tDsVpy7PmDE2n6ZAO0rHpUpbqz0</td>\n",
       "      <td>youtube#videoListResponse</td>\n",
       "      <td>{'resultsPerPage': 40, 'totalResults': 40}</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>otOtu8WFJDFkzdBR_PG0LptIkK4</td>\n",
       "      <td>youtube#videoListResponse</td>\n",
       "      <td>{'resultsPerPage': 37, 'totalResults': 37}</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>etag</th>\n      <th>kind</th>\n      <th>pageInfo</th>\n      <th>pageInfo.resultsPerPage</th>\n      <th>pageInfo.totalResults</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U0fncx_GV9jD5SKQr15LMvwuPcs</td>\n      <td>youtube#videoListResponse</td>\n      <td>{'resultsPerPage': 38, 'totalResults': 38}</td>\n      <td>38</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LZV6LlN3-4QwaIGfe9KBxl0cJvE</td>\n      <td>youtube#videoListResponse</td>\n      <td>{'resultsPerPage': 38, 'totalResults': 38}</td>\n      <td>38</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ou4xXi-09RdImAeo1EFJC01i8iM</td>\n      <td>youtube#videoListResponse</td>\n      <td>{'resultsPerPage': 43, 'totalResults': 43}</td>\n      <td>43</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tDsVpy7PmDE2n6ZAO0rHpUpbqz0</td>\n      <td>youtube#videoListResponse</td>\n      <td>{'resultsPerPage': 40, 'totalResults': 40}</td>\n      <td>40</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>otOtu8WFJDFkzdBR_PG0LptIkK4</td>\n      <td>youtube#videoListResponse</td>\n      <td>{'resultsPerPage': 37, 'totalResults': 37}</td>\n      <td>37</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "exploded_df = reduce(\n",
    "  lambda memo_df, col_name: memo_df.withColumn(col_name, F.col(col_name)),\n",
    "  walkSchema(df.schema), df\n",
    ").drop('items')\n",
    "\n",
    "exploded_df.limit(5).toPandas()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "youtube_part2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
